{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./train.data.jsonl\", \"r\") as f:\n",
    "    raw_lines_train = f.readlines()\n",
    "with open(\"./train.label.json\", \"r\") as f:\n",
    "    raw_labels_train = f.readlines()\n",
    "\n",
    "with open(\"./dev.data.jsonl\", \"r\") as f:\n",
    "    raw_lines_dev = f.readlines()\n",
    "\n",
    "with open(\"./dev.label.json\", \"r\") as f:\n",
    "    raw_labels_dev = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_lines_train = [json.loads(line) for line in raw_lines_train]\n",
    "json_labels_train = [json.loads(line) for line in raw_labels_train][0]\n",
    "\n",
    "json_lines_dev = [json.loads(line) for line in raw_lines_dev]\n",
    "json_labels_dev = [json.loads(line) for line in raw_labels_dev][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAR ME\n"
     ]
    }
   ],
   "source": [
    "print(\"CLEAR ME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4641\n",
      "580\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_lines_train))\n",
    "print(len(raw_lines_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 38\n",
      "30 36\n",
      "16 124\n",
      "14 103\n",
      "13 129\n",
      "21 151\n",
      "5 179\n",
      "12 136\n",
      "9 169\n",
      "10 171\n",
      "19 233\n",
      "23 102\n",
      "26 45\n",
      "20 273\n",
      "18 155\n",
      "15 114\n",
      "28 36\n",
      "34 30\n",
      "11 149\n",
      "8 186\n",
      "32 30\n",
      "25 75\n",
      "4 194\n",
      "3 171\n",
      "1 276\n",
      "2 148\n",
      "36 23\n",
      "44 11\n",
      "6 181\n",
      "22 122\n",
      "50 9\n",
      "42 13\n",
      "46 11\n",
      "54 7\n",
      "17 124\n",
      "7 180\n",
      "24 79\n",
      "35 23\n",
      "43 9\n",
      "37 24\n",
      "48 9\n",
      "45 10\n",
      "59 4\n",
      "40 9\n",
      "56 5\n",
      "39 28\n",
      "27 47\n",
      "31 22\n",
      "33 22\n",
      "47 16\n",
      "53 10\n",
      "41 6\n",
      "38 17\n",
      "51 7\n",
      "55 7\n",
      "60 5\n",
      "52 8\n",
      "57 9\n",
      "58 4\n",
      "49 11\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_counts = defaultdict(int)\n",
    "\n",
    "for json_line in json_lines_train:\n",
    "    length_counts[len(json_line)] += 1\n",
    "\n",
    "(lx, ly) = ([], [])\n",
    "\n",
    "max_size = 0\n",
    "\n",
    "for (replies, num_replies) in length_counts.items():\n",
    "    max_size = max(max_size, replies)\n",
    "    if replies > 60:\n",
    "        continue\n",
    "    lx.append(replies)\n",
    "    ly.append(num_replies)\n",
    "    print(replies, num_replies)\n",
    "    \n",
    "plt.bar(lx, ly)\n",
    "print(length_counts[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\cupy\\_environment.py:210: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_present = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "MAX_FEATURES = 40\n",
    "\n",
    "def process_lines(lines):\n",
    "    myX = []\n",
    "    i = 0\n",
    "    shape = None\n",
    "\n",
    "    for doc in nlp.pipe(map(lambda x: x['text'], lines[:MAX_FEATURES])):\n",
    "        shape = doc._.trf_data.tensors[-1].shape[1]\n",
    "        myX.append(doc._.trf_data.tensors[-1].reshape(shape))\n",
    "        i += 1\n",
    "\n",
    "        # Add zero matrices to the remaining\n",
    "    for _ in range(i, MAX_FEATURES):\n",
    "        myX.append(np.zeros(shape))\n",
    "    \n",
    "    return myX\n",
    "\n",
    "def getXY():\n",
    "    X = []\n",
    "    Y = []\n",
    "    MAX_FEATURES = 40\n",
    "    for lines in tqdm(json_lines_train):\n",
    "        Y.append(0 if json_labels_train[lines[0]['id_str']] == 'non-rumour' else 1) \n",
    "        X.append(process_lines(lines))\n",
    "    return X, Y\n",
    "\n",
    "if files_present:\n",
    "    X = np.load(\"./train_matrix.npy\")\n",
    "    Y = np.load(\"./train_labels.npy\")\n",
    "else:\n",
    "    X, Y = getXY()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "myX = np.expand_dims(X, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4641, 40, 768, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '!', 'world', '<', '3', 'i', \"'\", 'm', 'kinda', 'keen']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(json_lines, json_labels):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for lines in json_lines:\n",
    "        X.append(list(map(lambda x: x['text'], lines)))\n",
    "        Y.append(0 if json_labels[lines[0]['id_str']] == 'non-rumour' else 1)\n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getText(json_lines_train, json_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hostage taker in Sydney cafe demands ISIS flag and call with Australian PM, Sky News reports. http://t.co/a2vgrn30Xh #sydneysiege',\n",
       " \"@cnni So they noticed they had the wrong flag and decided to ask for the right one... Wow, these 'terrorists' sound supremely incompetent.\",\n",
       " '@harryjohal1982 @cnni bouyt time u didd',\n",
       " 'MT “@cnni: Hostage taker in Sydney cafe demands ISIS flag and call with Australian PM, Sky News reports. #sydneysiege”',\n",
       " '@rupayanb @SohamDeGuevara @cnni How to Create an \"Islamic Enemy\" - http://t.co/mzxzVWDkH1',\n",
       " '@cnni avnt they shot him yet',\n",
       " '@cnni just send em a Bart Simson flag w/the👉middle finger and a bullet',\n",
       " \"@NickWaite7 @cnni we don't shoot in Australia\",\n",
       " '@cnni Shoot him',\n",
       " '@harryjohal1982 Yes, and it would seem the terrorists are positively counting on that.   @NickWaite7 @cnni',\n",
       " '@cnni must be shot in head through snipers.',\n",
       " '@cnni Yes, surely the Australian government has ISIS flags ready to give just for this moment.',\n",
       " \"@NickWaite7 @cnni it's crazy huh, they want to have a peaceful resolution then give him all the entitlements to make his life better 😜\",\n",
       " '“@cnni: Hostage taker in Sydney cafe demands ISIS flag and call with Australian PM, Sky News reports. http://t.co/mRghqDBf50 #sydneysiege”',\n",
       " \"@cnni he couldn't make his own eh? he needs some diapers and wet napkins as well I'd say.\",\n",
       " '@cnni 🍵☕coffee anyone??',\n",
       " '@cnni The free world burns as @BarackObama plays the flute.\\nThe weakest US Prez ever.',\n",
       " '@cnni I thought police asked media not to report demands. Why you giving these terrorists a voice?',\n",
       " '@heidicantwait @cnni @harryjohal1982 wats for breakfast in Sydney today',\n",
       " '@Pugnate @cnni One day black flag will fly on the UN Hq too.\\n@BarackObama playing the flute as world burns.',\n",
       " '@cnni Raytheon has made various #RF #weapons for decades: https://t.co/dlLu4QKngg … Similar to those used on #TargetedIndividuals',\n",
       " '@cnni Stick that ISIS flag up his ass.',\n",
       " '@cnni Strange times']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc [ENDSENT] def'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' [ENDSENT] '.join([\"abc\", \"def\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumour\n",
      "{\n",
      "  \"contributors\": null,\n",
      "  \"truncated\": false,\n",
      "  \"text\": \"BREAKING: Hostages taken in central #Sydney caf\\u00e9, jihadist flag held against window http://t.co/7hJUmKz1eY http://t.co/TeK7ZjFHm6\",\n",
      "  \"in_reply_to_status_id\": null,\n",
      "  \"id\": 544285296565948416,\n",
      "  \"favorite_count\": 123,\n",
      "  \"source\": \"<a href=\\\"https://about.twitter.com/products/tweetdeck\\\" rel=\\\"nofollow\\\">TweetDeck</a>\",\n",
      "  \"retweeted\": false,\n",
      "  \"coordinates\": null,\n",
      "  \"entities\": {\n",
      "    \"symbols\": [],\n",
      "    \"media\": [\n",
      "      {\n",
      "        \"expanded_url\": \"http://twitter.com/RT_com/status/544285296565948416/photo/1\",\n",
      "        \"display_url\": \"pic.twitter.com/TeK7ZjFHm6\",\n",
      "        \"url\": \"http://t.co/TeK7ZjFHm6\",\n",
      "        \"media_url_https\": \"https://pbs.twimg.com/media/B42uliVCIAEC_uo.jpg\",\n",
      "        \"id_str\": \"544283089875116033\",\n",
      "        \"sizes\": {\n",
      "          \"large\": {\n",
      "            \"h\": 337,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 600\n",
      "          },\n",
      "          \"small\": {\n",
      "            \"h\": 190,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 340\n",
      "          },\n",
      "          \"medium\": {\n",
      "            \"h\": 337,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 600\n",
      "          },\n",
      "          \"thumb\": {\n",
      "            \"h\": 150,\n",
      "            \"resize\": \"crop\",\n",
      "            \"w\": 150\n",
      "          }\n",
      "        },\n",
      "        \"indices\": [\n",
      "          107,\n",
      "          129\n",
      "        ],\n",
      "        \"type\": \"photo\",\n",
      "        \"id\": 544283089875116033,\n",
      "        \"media_url\": \"http://pbs.twimg.com/media/B42uliVCIAEC_uo.jpg\"\n",
      "      }\n",
      "    ],\n",
      "    \"hashtags\": [\n",
      "      {\n",
      "        \"indices\": [\n",
      "          36,\n",
      "          43\n",
      "        ],\n",
      "        \"text\": \"Sydney\"\n",
      "      }\n",
      "    ],\n",
      "    \"user_mentions\": [],\n",
      "    \"trends\": [],\n",
      "    \"urls\": [\n",
      "      {\n",
      "        \"url\": \"http://t.co/7hJUmKz1eY\",\n",
      "        \"indices\": [\n",
      "          84,\n",
      "          106\n",
      "        ],\n",
      "        \"expanded_url\": \"http://RT.COM\",\n",
      "        \"display_url\": \"RT.COM\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"in_reply_to_screen_name\": null,\n",
      "  \"id_str\": \"544285296565948416\",\n",
      "  \"retweet_count\": 814,\n",
      "  \"in_reply_to_user_id\": null,\n",
      "  \"favorited\": false,\n",
      "  \"user\": {\n",
      "    \"follow_request_sent\": null,\n",
      "    \"profile_use_background_image\": true,\n",
      "    \"default_profile_image\": false,\n",
      "    \"id\": 64643056,\n",
      "    \"verified\": true,\n",
      "    \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/423103093069205504/eTXULFRS_normal.png\",\n",
      "    \"profile_sidebar_fill_color\": \"EBEBEB\",\n",
      "    \"profile_text_color\": \"000000\",\n",
      "    \"followers_count\": 824420,\n",
      "    \"profile_sidebar_border_color\": \"FFFFFF\",\n",
      "    \"id_str\": \"64643056\",\n",
      "    \"profile_background_color\": \"1D1D1D\",\n",
      "    \"listed_count\": 13368,\n",
      "    \"profile_background_image_url_https\": \"https://pbs.twimg.com/profile_background_images/448107225769193472/16jIvlg2.jpeg\",\n",
      "    \"utc_offset\": 14400,\n",
      "    \"statuses_count\": 102584,\n",
      "    \"description\": \"RT, the global news network, broadcasts from Moscow, London and Washington studios to over 100 countries.\",\n",
      "    \"friends_count\": 460,\n",
      "    \"location\": \"\",\n",
      "    \"profile_link_color\": \"3D990F\",\n",
      "    \"profile_image_url\": \"http://pbs.twimg.com/profile_images/423103093069205504/eTXULFRS_normal.png\",\n",
      "    \"following\": null,\n",
      "    \"geo_enabled\": false,\n",
      "    \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/64643056/1409741388\",\n",
      "    \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/448107225769193472/16jIvlg2.jpeg\",\n",
      "    \"name\": \"RT\",\n",
      "    \"lang\": \"en\",\n",
      "    \"profile_background_tile\": false,\n",
      "    \"favourites_count\": 23,\n",
      "    \"screen_name\": \"RT_com\",\n",
      "    \"notifications\": null,\n",
      "    \"url\": \"http://RT.com\",\n",
      "    \"created_at\": \"Tue Aug 11 06:12:45 +0000 2009\",\n",
      "    \"contributors_enabled\": false,\n",
      "    \"time_zone\": \"Moscow\",\n",
      "    \"protected\": false,\n",
      "    \"default_profile\": false,\n",
      "    \"is_translator\": false\n",
      "  },\n",
      "  \"geo\": null,\n",
      "  \"in_reply_to_user_id_str\": null,\n",
      "  \"possibly_sensitive\": false,\n",
      "  \"lang\": \"en\",\n",
      "  \"created_at\": \"Mon Dec 15 00:18:21 +0000 2014\",\n",
      "  \"filter_level\": \"low\",\n",
      "  \"in_reply_to_status_id_str\": null,\n",
      "  \"place\": null,\n",
      "  \"extended_entities\": {\n",
      "    \"media\": [\n",
      "      {\n",
      "        \"expanded_url\": \"http://twitter.com/RT_com/status/544285296565948416/photo/1\",\n",
      "        \"display_url\": \"pic.twitter.com/TeK7ZjFHm6\",\n",
      "        \"url\": \"http://t.co/TeK7ZjFHm6\",\n",
      "        \"media_url_https\": \"https://pbs.twimg.com/media/B42uliVCIAEC_uo.jpg\",\n",
      "        \"id_str\": \"544283089875116033\",\n",
      "        \"sizes\": {\n",
      "          \"large\": {\n",
      "            \"h\": 337,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 600\n",
      "          },\n",
      "          \"small\": {\n",
      "            \"h\": 190,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 340\n",
      "          },\n",
      "          \"medium\": {\n",
      "            \"h\": 337,\n",
      "            \"resize\": \"fit\",\n",
      "            \"w\": 600\n",
      "          },\n",
      "          \"thumb\": {\n",
      "            \"h\": 150,\n",
      "            \"resize\": \"crop\",\n",
      "            \"w\": 150\n",
      "          }\n",
      "        },\n",
      "        \"indices\": [\n",
      "          107,\n",
      "          129\n",
      "        ],\n",
      "        \"type\": \"photo\",\n",
      "        \"id\": 544283089875116033,\n",
      "        \"media_url\": \"http://pbs.twimg.com/media/B42uliVCIAEC_uo.jpg\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "index = 26\n",
    "\n",
    "print(json_labels_train[json_lines_train[index][0]['id_str']])\n",
    "print(json.dumps(json_lines_train[index][0], indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-rumour'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_labels_train['525003253185277952']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important factors\n",
    "* Information Density\n",
    "* Follower count\n",
    "* Verified or not - We are fully confident that this is not an artifical actor, this likely is a good spam filtering feature. \n",
    "* Is news channel or not\n",
    "* feelings or factual ? Does it make a statement or is it vague ? This is vaguely correlated with sentiment analysis. Scores on the extreme ends of sentiment analysis tend to be feeling heavy while vague statements tend to be statement heavy. We can detect users that try to assert facts through this.\n",
    "* Profanity, users that are spreading \"truths\" can be detected by the lack of profanity and spelling mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentlen = list(map(lambda x: len(x), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22297fb9dc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.displot(sentlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = sum(list(map(lambda x: list(map(lambda y: len(y), x)), X)), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22300b7ee80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "bert = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_plus(\"hello world how are you, I am doing fine\", \n",
    "                               max_length=SEQ_LEN, \n",
    "                               truncation=True, \n",
    "                               padding='max_length', \n",
    "                               add_special_tokens=True, \n",
    "                               return_token_type_ids=False,\n",
    "                               return_attention_mask=True,\n",
    "                               return_tensors=\"tf\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 140), dtype=int32, numpy=\n",
       "array([[ 101, 7592, 2088, 2129, 2024, 2017, 1010, 1045, 2572, 2725, 2986,\n",
       "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0]])>, 'attention_mask': <tf.Tensor: shape=(1, 140), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "XConcat = [' [SEP] '.join(map(lambda x: x.replace(\".\", \"\"), x_)) for x_ in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xids = np.zeros((len(X), SEQ_LEN))\n",
    "Xmask = np.zeros((len(X), SEQ_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seq in enumerate(XConcat):\n",
    "    tokens = tokenizer.encode_plus(seq, \n",
    "                               max_length=SEQ_LEN, \n",
    "                               truncation=True, \n",
    "                               padding='max_length', \n",
    "                               add_special_tokens=True, \n",
    "                               return_token_type_ids=False,\n",
    "                               return_attention_mask=True,\n",
    "                               return_tensors=\"tf\"\n",
    "                              )\n",
    "    Xids[i, :], Xmask[i, :] = tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4641, 140)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray(Y)\n",
    "Y = np.expand_dims(Y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(140,), dtype=float64, numpy=\n",
      "array([  101.,  2129.,  2000.,  6869.,  2000.,  1996., 25303.,  2886.,\n",
      "        2006.,  4918.,  2002.,  2497.,  3527.,  1029.,  2296.,  3780.,\n",
      "        1999.,  1996.,  2489.,  2088.,  2323.,  6140.,  2023.,  8299.,\n",
      "        1024.,  1013.,  1013., 22975.,  2080.,  1013.,  8040.,  2475.,\n",
      "        4140.,  2575.,  2509.,  2546.,  2575.,  3501.,   102.,  1030.,\n",
      "       28354.,  1035.,  3420.,  1030.,  1047.,  7946., 21426., 12718.,\n",
      "        4135.,  9397.,  5181.,  3830.,  3087.,  2027.,  2123.,  1005.,\n",
      "        1056.,  2066.,  2004.,  3424.,  1011.,  4100.,  2618.,  1998.,\n",
      "        3049.,  2127.,  2008.,  2711.,  1013.,  2194.,  2003.,  2736.,\n",
      "         102.,  1030., 28354.,  1035.,  3420.,  1030.,  1047.,  7946.,\n",
      "       21426., 12718.,  4135.,  9397.,  2053.,  2028.,  2515.,   102.,\n",
      "        1030., 28354.,  1035.,  3420.,  1001., 10047.,  7507., 12190.,\n",
      "        2666.,  5369.,  2497.,  3527.,   102.,  1030.,  1047.,  7946.,\n",
      "       21426., 12718.,  4135.,  9397.,  4487.,  9284.,   102.,  1030.,\n",
      "       24665., 29266.,  1035., 26319.,  1030.,  3419.,  1035., 11417.,\n",
      "        2078.,  2054.,  7036.,  7486., 11276.,  2000.,  2424., 23979.,\n",
      "        2003.,  2019.,  2012., 21735.,  5462.,  1999.,  2037.,  2171.,\n",
      "        1010.,  2025.,  1037.,   102.])>, <tf.Tensor: shape=(140,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.])>, <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(input_ids, masks, label):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(140,), dtype=float64, numpy=\n",
      "array([  101.,  2129.,  2000.,  6869.,  2000.,  1996., 25303.,  2886.,\n",
      "        2006.,  4918.,  2002.,  2497.,  3527.,  1029.,  2296.,  3780.,\n",
      "        1999.,  1996.,  2489.,  2088.,  2323.,  6140.,  2023.,  8299.,\n",
      "        1024.,  1013.,  1013., 22975.,  2080.,  1013.,  8040.,  2475.,\n",
      "        4140.,  2575.,  2509.,  2546.,  2575.,  3501.,   102.,  1030.,\n",
      "       28354.,  1035.,  3420.,  1030.,  1047.,  7946., 21426., 12718.,\n",
      "        4135.,  9397.,  5181.,  3830.,  3087.,  2027.,  2123.,  1005.,\n",
      "        1056.,  2066.,  2004.,  3424.,  1011.,  4100.,  2618.,  1998.,\n",
      "        3049.,  2127.,  2008.,  2711.,  1013.,  2194.,  2003.,  2736.,\n",
      "         102.,  1030., 28354.,  1035.,  3420.,  1030.,  1047.,  7946.,\n",
      "       21426., 12718.,  4135.,  9397.,  2053.,  2028.,  2515.,   102.,\n",
      "        1030., 28354.,  1035.,  3420.,  1001., 10047.,  7507., 12190.,\n",
      "        2666.,  5369.,  2497.,  3527.,   102.,  1030.,  1047.,  7946.,\n",
      "       21426., 12718.,  4135.,  9397.,  4487.,  9284.,   102.,  1030.,\n",
      "       24665., 29266.,  1035., 26319.,  1030.,  3419.,  1035., 11417.,\n",
      "        2078.,  2054.,  7036.,  7486., 11276.,  2000.,  2424., 23979.,\n",
      "        2003.,  2019.,  2012., 21735.,  5462.,  1999.,  2037.,  2171.,\n",
      "        1010.,  2025.,  1037.,   102.])>, 'attention_mask': <tf.Tensor: shape=(140,), dtype=float64, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.])>}, <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dataset = dataset.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002228BBE4280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002228BBE4280>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(SEQ_LEN), name='attention_mask', dtype='int32')\n",
    "embeddings = bert(input_ids, attention_mask=mask)[0]\n",
    "\n",
    "TFX = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "TFX = tf.keras.layers.BatchNormalization()(TFX)\n",
    "TFX = tf.keras.layers.Dense(128, activation='relu')(TFX)\n",
    "TFX = tf.keras.layers.Dropout(0.1)(TFX)\n",
    "TFX = tf.keras.layers.Dense(32, activation='relu')(TFX)\n",
    "TFY = tf.keras.layers.Dense(1, activation='softmax', name='outputs')(TFX)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=TFY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 140)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 140)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 768)          3072        global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 1)            33          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,587,905\n",
      "Trainable params: 109,586,369\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "acc = tf.keras.metrics.BinaryCrossentropy('accuracy')\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_LEN = len([0 for batch in dataset])\n",
    "SPLIT = 0.9  # 90-10 split\n",
    "\n",
    "train = batched_dataset.take(round(DS_LEN*SPLIT))  # get first 90% of batches\n",
    "val = batched_dataset.skip(round(DS_LEN*SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "12/37 [========>.....................] - ETA: 15:21 - loss: 0.7047 - accuracy: 0.7047"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, validation_data=val, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(4480,), dtype=float64, numpy=array([ 101., 2129., 2000., ...,    0.,    0.,    0.])>, 'attention_mask': <tf.Tensor: shape=(4480,), dtype=float64, numpy=array([1., 1., 1., ..., 0., 0., 0.])>}, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4641, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_memory_usage_in_bytes(model, *, batch_size: int):\n",
    "    \"\"\"\n",
    "    Return the estimated memory usage of a given Keras model in bytes.\n",
    "    This includes the model weights and layers, but excludes the dataset.\n",
    "\n",
    "    The model shapes are multipled by the batch size, but the weights are not.\n",
    "\n",
    "    Args:\n",
    "        model: A Keras model.\n",
    "        batch_size: The batch size you intend to run the model with. If you\n",
    "            have already specified the batch size in the model itself, then\n",
    "            pass `1` as the argument here.\n",
    "    Returns:\n",
    "        An estimate of the Keras model's memory usage in bytes.\n",
    "\n",
    "    \"\"\"\n",
    "    default_dtype = tf.keras.backend.floatx()\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            internal_model_mem_count += keras_model_memory_usage_in_bytes(\n",
    "                layer, batch_size=batch_size\n",
    "            )\n",
    "        single_layer_mem = tf.as_dtype(layer.dtype or default_dtype).size\n",
    "        out_shape = layer.output_shape\n",
    "        if isinstance(out_shape, list):\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = sum(\n",
    "        [tf.keras.backend.count_params(p) for p in model.trainable_weights]\n",
    "    )\n",
    "    non_trainable_count = sum(\n",
    "        [tf.keras.backend.count_params(p) for p in model.non_trainable_weights]\n",
    "    )\n",
    "\n",
    "    total_memory = (\n",
    "        batch_size * shapes_mem_count\n",
    "        + internal_model_mem_count\n",
    "        + trainable_count\n",
    "        + non_trainable_count\n",
    "    )\n",
    "    return total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The layer has never been called and thus has no defined output shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-6f23d3e4489b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras_model_memory_usage_in_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-9b06d9db9d4c>\u001b[0m in \u001b[0;36mkeras_model_memory_usage_in_bytes\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             internal_model_mem_count += keras_model_memory_usage_in_bytes(\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             )\n",
      "\u001b[1;32m<ipython-input-98-9b06d9db9d4c>\u001b[0m in \u001b[0;36mkeras_model_memory_usage_in_bytes\u001b[1;34m(model, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m             )\n\u001b[0;32m     25\u001b[0m         \u001b[0msingle_layer_mem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdefault_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mout_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mout_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36moutput_shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2226\u001b[0m     \"\"\"\n\u001b[0;32m   2227\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2228\u001b[1;33m       raise AttributeError('The layer has never been called '\n\u001b[0m\u001b[0;32m   2229\u001b[0m                            'and thus has no defined output shape.')\n\u001b[0;32m   2230\u001b[0m     all_output_shapes = set(\n",
      "\u001b[1;31mAttributeError\u001b[0m: The layer has never been called and thus has no defined output shape."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
